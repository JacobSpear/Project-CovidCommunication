{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "import pymongo\n",
    "import csv\n",
    "\n",
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n",
    "\n",
    "\n",
    "def tweet(url):\n",
    "    #SOURCE: https://medium.com/@dawranliou/twitter-scraper-tutorial-with-python-requests-beautifulsoup-and-selenium-part-2-b38d849b07fe\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "    body = driver.find_element_by_tag_name('body')\n",
    "\n",
    "    links = set()\n",
    "\n",
    "    #body.send_keys(Keys.PAGE_DOWN)\n",
    "    current_html = driver.page_source\n",
    "    soup = bs(current_html,'lxml')\n",
    "\n",
    "    return soup.find('title').text\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#Scrapes many tweets\n",
    "def twitter(url,num_tweets):\n",
    "    #SOURCE: https://medium.com/@dawranliou/twitter-scraper-tutorial-with-python-requests-beautifulsoup-and-selenium-part-2-b38d849b07fe\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "    body = driver.find_element_by_tag_name('body')\n",
    "\n",
    "    links = set()\n",
    "\n",
    "    for i in range(num_tweets):\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        mars_twitter_html = driver.page_source\n",
    "        soup = bs(mars_twitter_html,'lxml')\n",
    "        current_lines = pd.Series([x['href'] for x in soup.find_all(class_='css-4rbku5 css-18t94o4 css-901oao r-1re7ezh r-1loqt21 r-1q142lx r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-3s2u2q r-qvutc0')])\n",
    "        links.update(current_lines)\n",
    "\n",
    "    filepath = 'links_scraped.html'\n",
    "    with open(filepath,'w') as text:\n",
    "        for line in links:\n",
    "            try:\n",
    "                text.write(str(line))\n",
    "                text.write('\\n')\n",
    "            except UnicodeEncodeError:\n",
    "                text.write('line skipped')\n",
    "                text.write('\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    filepath2= 'all_tweets.html'\n",
    "    with open(filepath2,'w') as text:\n",
    "        for line in links:\n",
    "            response = tweet(f'https://twitter.com{line}')\n",
    "            for char in response:\n",
    "                try:\n",
    "                    text.write(char)\n",
    "                except UnicodeEncodeError:\n",
    "                    pass\n",
    "            text.write('\\n')\n",
    "    \n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
