{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from time import sleep\n",
    "import pymongo\n",
    "import csv\n",
    "import os   \n",
    "from datetime import datetime, date\n",
    "import dateutil.parser as dp\n",
    "import numpy as np\n",
    "\n",
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n",
    "\n",
    "def get_date(my_str):\n",
    "    str_time = dp.parse(my_str).replace(tzinfo=None)\n",
    "    return datetime.strftime(str_time,\"%Y-%m-%d\")\n",
    "\n",
    "def feb_or_later(my_str):\n",
    "    str_time = dp.parse(my_str).replace(tzinfo=None)\n",
    "    start_time = dp.parse('2020-02-01T00:00:00.000Z').replace(tzinfo=None)\n",
    "    return (str_time >= start_time)\n",
    "\n",
    "\n",
    "def parse_tweet(tweet):\n",
    "    entry = {}\n",
    "            \n",
    "    #Get Time of Tweet\n",
    "    entry['time'] = tweet.find(\"time\")['datetime']\n",
    "\n",
    "\n",
    "    # Gets Text of Tweet\n",
    "    # L is the \"layers\" of the tweet.  L[2] is the text itself.\n",
    "    Layers = []\n",
    "    Layers.append(tweet.findAll(\"div\",recursive=False)[1])\n",
    "    Layers.append(Layers[0].findAll(\"div\",recursive=False)[1])\n",
    "    Layers.append(Layers[1].findAll(\"div\",recursive=False)[len(Layers[1])-3].text)\n",
    "    entry['text'] = Layers[2]\n",
    "    \n",
    "    #Checks For Tweets about COVID-19\n",
    "    keywords = ['covid','virus','corona','distancing','masks',\n",
    "                'ppe','ventilators','flatten','test',\n",
    "                'healthcare professionals','healthcare workers',\n",
    "                'patients','spread','stay home','stayhome','unprecedented']\n",
    "\n",
    "    about_covid = False\n",
    "    \n",
    "    for word in keywords:\n",
    "        if word in entry['text'].lower():\n",
    "            about_covid = True\n",
    "            break\n",
    "    \n",
    "    entry['about_covid']=about_covid\n",
    "\n",
    "\n",
    "    #Get Handle\n",
    "    entry['handle'] = Layers[0].findAll('a')[0]['href']\n",
    "\n",
    "\n",
    "    #Get Is_Retweet\n",
    "    info = tweet.find_parent('div').find('div').text\n",
    "    entry['is_retweet'] = ('retweet' in info.lower())\n",
    "    \n",
    "    return entry\n",
    "\n",
    "#Scrapes many tweets\n",
    "def twitter(url):\n",
    "    #SOURCE: https://medium.com/@dawranliou/twitter-scraper-tutorial-with-python-requests-beautifulsoup-and-selenium-part-2-b38d849b07fe\n",
    "    chrome_options = Options()  \n",
    "    chrome_options.add_argument(\"--headless\") \n",
    "    driver = webdriver.Chrome(executable_path=os.path.abspath(\"chromedriver\"), options=chrome_options)  \n",
    "    driver.get(url)\n",
    "    print('here')\n",
    "    body = driver.find_element_by_tag_name('body')\n",
    "    sleep(4)\n",
    "    \n",
    "    \n",
    "    tweets = []\n",
    "    last_tweet_date = date.today()\n",
    "    run = True\n",
    "    while run:\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        html = driver.page_source\n",
    "        soup = bs(html,'lxml')\n",
    "        timeline = soup.findAll(\"div\", {\"data-testid\" : \"tweet\"})\n",
    "        \n",
    "        for tweet in timeline:\n",
    "            if len(tweets) > 20:\n",
    "                run = False\n",
    "            try:\n",
    "                response = parse_tweet(tweet)\n",
    "                \n",
    "                if not response['is_retweet']:\n",
    "                    tweet_time = response['time']\n",
    "                    run = feb_or_later(tweet_time)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                if run:\n",
    "                    add = True\n",
    "                    for tweet in tweets:\n",
    "                        if ((response['time']==tweet['time']) \n",
    "                            and (response['handle']==tweet['handle'])):\n",
    "                            add = False\n",
    "                            break                    \n",
    "           \n",
    "                    if add:\n",
    "                        if not response['is_retweet']:\n",
    "                            last_tweet_date = get_date(response['time'])\n",
    "                        \n",
    "                        response['tweet_date'] = last_tweet_date\n",
    "                        tweets.append(response)\n",
    "                \n",
    "                \n",
    "            except TypeError:\n",
    "                #This allows us to ignore deleted tweets\n",
    "                pass\n",
    "\n",
    "\n",
    "    driver.close()\n",
    "    return tweets\n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
